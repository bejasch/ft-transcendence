---
name: ft-transcendence

# https://github.com/docker/compose/pull/5140
x-env-watch: &env-watch
    WATCH: "${WATCH:-0}"

x-env-caddy-backend: &env-caddy-backend
    <<: *env-watch
    BACKEND_PORT: "${BACKEND_PORT:-3000}"
    DOMAINS: "${DOMAINS:-localhost}"

x-env-files: &env-files
    - config.env

services:
    caddy:
        build: "./caddy/"
        container_name: caddy
        restart: unless-stopped
        ports:
            - "${HTTP_PORT:-8080}:8080"
            - "${HTTPS_PORT:-8443}:8443"
        networks:
            ft-transcendence-net:
                ipv4_address: &caddy-ip 10.42.42.1
        volumes:
            - "caddy-data:/frontend/.local/share/caddy/"
            - "frontend:/frontend/dist/:ro"
        environment:
            <<: *env-caddy-backend
            HTTP_DOMAINS: "${HTTP_DOMAINS:-http://localhost}"
            HTTPS_DOMAINS: "${HTTPS_DOMAINS:-https://localhost}"
            CADDY_EXTRA_GLOBAL_DIRECTIVES: "${CADDY_EXTRA_GLOBAL_DIRECTIVES:-}"
            CADDY_EXTRA_SITE_DIRECTIVES: "${CADDY_EXTRA_SITE_DIRECTIVES:-}"
        depends_on:
            - frontend
            - backend
        develop:
            watch:
                - path: "./caddy/Caddyfile"
                  action: sync
                  target: "/etc/caddy/Caddyfile"
        env_file: *env-files

    frontend:
        build: "./frontend/"
        container_name: frontend
        restart: no
        ports:
            - "${LIVE_RELOAD_PORT:-35729}:${LIVE_RELOAD_PORT:-35729}"
        environment: *env-watch
        volumes:
            - "frontend:/frontend/dist/"
        develop:
            watch:
                - path: "./frontend/"
                  action: sync # Might fail on MacOS when node_modules is touched, use `rebuild` as fallback
                  target: "/frontend/"
                - path: "./frontend/package.json"
                  action: rebuild
                  target: "/frontend/package.json"
                - path: "./frontend/esbuild.config.js"
                  action: rebuild
                  target: "/frontend/esbuild.config.js"
                - path: "./frontend/reload-server.js"
                  action: rebuild
                  target: "/frontend/reload-server.js"
        env_file: *env-files
        depends_on:
            backend:
                condition: service_healthy

    backend:
        build: "./backend/"
        container_name: backend
        restart: no # cannot restart because of expiring vault token
        networks:
            ft-transcendence-net:
                ipv4_address: &backend-ip 10.42.42.2
        environment:
            <<: *env-caddy-backend
            NODE_ENV: "${NODE_ENV:-development}"
            DB_PATH: "${DB_PATH:-}"
            LOG_LEVEL: "${LOG_LEVEL:-debug}"

            LOGSTASH_HOST: ${LOGSTASH_HOST:-}
            LOGSTASH_PORT: "${LOGSTASH_PORT:-5050}"
        volumes:
            - "drizzle:/backend/drizzle/"
            - "frontend:/frontend/dist/"
            - "./.secrets/backend_vault_token:/run/secrets/backend_vault_token"
        depends_on:
            vault:
                restart: true
                condition: service_healthy
            logstash:
                restart: true
                condition: service_healthy
                required: false
        develop:
            watch:
                - path: "./backend/"
                  action: sync # Might fail on MacOS when node_modules is touched, use `rebuild` as fallback
                  target: "/backend/"
                - path: "./backend/package.json"
                  action: rebuild
                  target: "/backend/package.json"
                - path: "./backend/esbuild.config.js"
                  action: rebuild
                  target: "/backend/esbuild.config.js"
        env_file: *env-files

    elasticsearch:
        profiles: [elk]
        build: "./elk/elasticsearch/"
        container_name: elasticsearch
        volumes:
            - "elasticsearch-data:/usr/share/elasticsearch/data/"
            - "elasticsearch-certs:/usr/share/elasticsearch/config/certs/"
            - "./.secrets/elasticsearch_vault_token:/run/secrets/elasticsearch_vault_token"

            - "./elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro"
            - "./elk/elasticsearch/config/generate-certs.sh:/usr/share/elasticsearch/config/generate-certs.sh:ro"
            - "./elk/elasticsearch/config/startup.sh:/usr/share/elasticsearch/config/startup.sh:ro"
            - "./elk/elasticsearch/config/ilm-policy.json:/usr/share/elasticsearch/config/ilm-policy.json:ro"
            - "./elk/elasticsearch/setup-single-node.sh:/usr/share/elasticsearch/setup-single-node.sh:ro"
        user: root # Run as root to ensure we can set permissions
        ports:
            - "9200:9200"
        networks:
            ft-transcendence-net:
                ipv4_address: &elasticsearch-ip 10.42.42.3
        depends_on:
            vault:
                restart: true
                condition: service_healthy
        restart: no # cannot restart because of expiring vault token

    logstash:
        profiles: [elk]
        build: "./elk/logstash/"
        container_name: logstash
        volumes:
            - "logstash-data:/usr/share/logstash/data/"
            - "elasticsearch-certs:/etc/logstash/config/certs/"
            - "./.secrets/logstash_vault_token:/run/secrets/logstash_vault_token"

            - "./elk/logstash/pipeline/:/usr/share/logstash/pipeline/:ro"
            - "./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro"
            - "./elk/logstash/scripts/import-logstash-ca.sh:/usr/local/bin/import-logstash-ca.sh:ro"
        ports:
            - "5050:5050/tcp"
            - "5050:5050/udp"
            - "9600:9600"
        networks:
            ft-transcendence-net:
                ipv4_address: &logstash-ip 10.42.42.4
        depends_on:
            elasticsearch:
                condition: service_healthy
            vault:
                restart: true
                condition: service_healthy
        restart: no # cannot restart because of expiring vault token
        healthcheck:
            test:
                [
                    "CMD",
                    "curl",
                    "--no-progress-meter",
                    "--fail",
                    "http://localhost:${LOGSTASH_API_PORT:-9600}/_node/stats",
                ]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s

    kibana:
        profiles: [elk]
        build: "./elk/kibana/"
        container_name: kibana
        ports:
            - "5601:5601"
        volumes:
            - "kibana-data:/usr/share/kibana/data"
            - "./.secrets/kibana_vault_token:/run/secrets/kibana_vault_token"

            - "./elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro"
            - "./elk/kibana/dashboards:/usr/share/kibana/dashboards/:ro"
            - "./elk/kibana/setup-dashboards.sh:/usr/share/kibana/setup-dashboards.sh:ro"
        networks:
            ft-transcendence-net:
                ipv4_address: &kibana-ip 10.42.42.5
        depends_on:
            elasticsearch:
                condition: service_healthy
            vault:
                restart: true
                condition: service_healthy
        restart: no # cannot restart because of expiring vault token
        healthcheck:
            test: ["CMD", "curl", "--fail", "http://localhost:${KIBANA_PORT:-5601}/api/status"]
            interval: 30s
            timeout: 10s
            retries: 5
            start_period: 30s

    vault:
        build:
            context: "./vault/"
            args:
                VAULT_API_PORT: ${VAULT_API_PORT:-8200}
        container_name: vault
        restart: unless-stopped
        networks:
            ft-transcendence-net:
                ipv4_address: &vault_ip 10.42.42.42
        extra_hosts:
            backend: *backend-ip
            caddy: *caddy-ip
            elasticsearch: *elasticsearch-ip
            logstash: *logstash-ip
            kibana: *kibana-ip
        cap_add:
            - IPC_LOCK
        volumes:
            - "vault-storage:/vault/file/"
            - "vault-secret:/vault/secret/"
            - "vault-logs:/vault/logs/"

            - "./.secrets/backend_vault_token:/run/secrets/backend_vault_token"
            - "./.secrets/elasticsearch_vault_token:/run/secrets/elasticsearch_vault_token"
            - "./.secrets/logstash_vault_token:/run/secrets/logstash_vault_token"
            - "./.secrets/kibana_vault_token:/run/secrets/kibana_vault_token"

            - "./env.json:/vault/config/env.json:ro"
        environment:
            <<: *env-watch
            LOGLEVEL: "debug"
            SAVE_UNSEAL_KEYS: "1"
            SAVE_ROOT_TOKEN: "1"
        tty: true
        develop:
            watch:
                - path: "./vault/entrypoint.sh"
                  action: sync+restart
                  target: "/entrypoint.sh"
                - path: "./vault/replace_json_templates.py"
                  action: sync+restart
                  target: "/replace_json_templates.py"
                - path: "./vault/healthcheck.sh"
                  action: sync+restart
                  target: "/healthcheck.sh"
                - path: "./vault/config.hcl.template"
                  action: sync+restart
                  target: "/vault/config/config.hcl.template"
                - path: "./vault/policies/"
                  action: sync+restart
                  target: "/vault/policies/"

volumes:
    vault-logs:
    vault-secret:
    vault-storage:
    caddy-data:
    drizzle:
    frontend:
    elasticsearch-data:
    elasticsearch-certs: # New volume for certificates
    logstash-data:
    kibana-data:

networks:
    ft-transcendence-net:
        enable_ipv6: false
        driver: bridge
        ipam:
            driver: default
            config:
                - subnet: 10.42.42.0/24
                  ip_range: 10.42.42.0/24
                  gateway: 10.42.42.254
